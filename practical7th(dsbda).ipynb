{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d13421a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2e98fd40",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = '''It was a Thursday, but it felt like a Monday to John. And John loved Mondays. He\n",
    "I should probably get another latte. I’ve just been sitting here with this empty cup. But\n",
    "John was always impatient on the weekends; he missed the formal structure of the business w\n",
    "Jesus, I’ve written another loser. '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7e0cf8da",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_split = text.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c8ad62ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'It was a Thursday, but it felt like a Monday to John. And John loved Mondays. He\\nI should probably get another latte. I’ve just been sitting here with this empty cup. But\\nJohn was always impatient on the weekends; he missed the formal structure of the business w\\nJesus, I’ve written another loser. '"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "da7ec93b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping taggers\\averaged_perceptron_tagger.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dcdfebbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "stop_words = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2bd02343",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('It', 'PRP'), ('Thursday', 'NNP'), (',', ','), ('felt', 'VBD'), ('like', 'IN'), ('Monday', 'NNP'), ('John', 'NNP'), ('.', '.')]\n",
      "[('And', 'CC'), ('John', 'NNP'), ('loved', 'VBD'), ('Mondays', 'NNP'), ('.', '.')]\n",
      "[('He', 'PRP'), ('I', 'PRP'), ('probably', 'RB'), ('get', 'VB'), ('another', 'DT'), ('latte', 'NN'), ('.', '.')]\n",
      "[('I', 'PRP'), ('’', 'VBP'), ('sitting', 'VBG'), ('empty', 'JJ'), ('cup', 'NN'), ('.', '.')]\n",
      "[('But', 'CC'), ('John', 'NNP'), ('always', 'RB'), ('impatient', 'JJ'), ('weekends', 'NNS'), (';', ':'), ('missed', 'VBN'), ('formal', 'JJ'), ('structure', 'NN'), ('business', 'NN'), ('w', 'NN'), ('Jesus', 'NNP'), (',', ','), ('I', 'PRP'), ('’', 'VBP'), ('written', 'VBN'), ('another', 'DT'), ('loser', 'NN'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "tokenized = sent_tokenize(text)\n",
    "for i in tokenized:\n",
    "    wordsList = nltk.word_tokenize(i)\n",
    "    wordsList = [w for w in wordsList if not w in stop_words]\n",
    "    tagged = nltk.pos_tag(wordsList)\n",
    "    print(tagged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2a0b29eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<WordListCorpusReader in 'C:\\\\Users\\\\admin\\\\AppData\\\\Roaming\\\\nltk_data\\\\corpora\\\\stopwords'>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "820e8b42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<WordListCorpusReader in 'C:\\\\Users\\\\admin\\\\AppData\\\\Roaming\\\\nltk_data\\\\corpora\\\\stopwords'>\n"
     ]
    }
   ],
   "source": [
    "print(stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "12f05b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.porter import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3313deeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "porter_stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e7537a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk_token = nltk.word_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0faf27fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual : It , Stem: it\n",
      "Actual : was , Stem: wa\n",
      "Actual : a , Stem: a\n",
      "Actual : Thursday , Stem: thursday\n",
      "Actual : , , Stem: ,\n",
      "Actual : but , Stem: but\n",
      "Actual : it , Stem: it\n",
      "Actual : felt , Stem: felt\n",
      "Actual : like , Stem: like\n",
      "Actual : a , Stem: a\n",
      "Actual : Monday , Stem: monday\n",
      "Actual : to , Stem: to\n",
      "Actual : John , Stem: john\n",
      "Actual : . , Stem: .\n",
      "Actual : And , Stem: and\n",
      "Actual : John , Stem: john\n",
      "Actual : loved , Stem: love\n",
      "Actual : Mondays , Stem: monday\n",
      "Actual : . , Stem: .\n",
      "Actual : He , Stem: he\n",
      "Actual : I , Stem: i\n",
      "Actual : should , Stem: should\n",
      "Actual : probably , Stem: probabl\n",
      "Actual : get , Stem: get\n",
      "Actual : another , Stem: anoth\n",
      "Actual : latte , Stem: latt\n",
      "Actual : . , Stem: .\n",
      "Actual : I , Stem: i\n",
      "Actual : ’ , Stem: ’\n",
      "Actual : ve , Stem: ve\n",
      "Actual : just , Stem: just\n",
      "Actual : been , Stem: been\n",
      "Actual : sitting , Stem: sit\n",
      "Actual : here , Stem: here\n",
      "Actual : with , Stem: with\n",
      "Actual : this , Stem: thi\n",
      "Actual : empty , Stem: empti\n",
      "Actual : cup , Stem: cup\n",
      "Actual : . , Stem: .\n",
      "Actual : But , Stem: but\n",
      "Actual : John , Stem: john\n",
      "Actual : was , Stem: wa\n",
      "Actual : always , Stem: alway\n",
      "Actual : impatient , Stem: impati\n",
      "Actual : on , Stem: on\n",
      "Actual : the , Stem: the\n",
      "Actual : weekends , Stem: weekend\n",
      "Actual : ; , Stem: ;\n",
      "Actual : he , Stem: he\n",
      "Actual : missed , Stem: miss\n",
      "Actual : the , Stem: the\n",
      "Actual : formal , Stem: formal\n",
      "Actual : structure , Stem: structur\n",
      "Actual : of , Stem: of\n",
      "Actual : the , Stem: the\n",
      "Actual : business , Stem: busi\n",
      "Actual : w , Stem: w\n",
      "Actual : Jesus , Stem: jesu\n",
      "Actual : , , Stem: ,\n",
      "Actual : I , Stem: i\n",
      "Actual : ’ , Stem: ’\n",
      "Actual : ve , Stem: ve\n",
      "Actual : written , Stem: written\n",
      "Actual : another , Stem: anoth\n",
      "Actual : loser , Stem: loser\n",
      "Actual : . , Stem: .\n"
     ]
    }
   ],
   "source": [
    "for w in nltk_token:\n",
    "    print(\"Actual : %s , Stem: %s\" %(w, porter_stemmer.stem(w)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9e83d2ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "wordnet_lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9218877e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\admin\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "242f12b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual : It , Lemme: It\n",
      "Actual : was , Lemme: wa\n",
      "Actual : a , Lemme: a\n",
      "Actual : Thursday , Lemme: Thursday\n",
      "Actual : , , Lemme: ,\n",
      "Actual : but , Lemme: but\n",
      "Actual : it , Lemme: it\n",
      "Actual : felt , Lemme: felt\n",
      "Actual : like , Lemme: like\n",
      "Actual : a , Lemme: a\n",
      "Actual : Monday , Lemme: Monday\n",
      "Actual : to , Lemme: to\n",
      "Actual : John , Lemme: John\n",
      "Actual : . , Lemme: .\n",
      "Actual : And , Lemme: And\n",
      "Actual : John , Lemme: John\n",
      "Actual : loved , Lemme: loved\n",
      "Actual : Mondays , Lemme: Mondays\n",
      "Actual : . , Lemme: .\n",
      "Actual : He , Lemme: He\n",
      "Actual : I , Lemme: I\n",
      "Actual : should , Lemme: should\n",
      "Actual : probably , Lemme: probably\n",
      "Actual : get , Lemme: get\n",
      "Actual : another , Lemme: another\n",
      "Actual : latte , Lemme: latte\n",
      "Actual : . , Lemme: .\n",
      "Actual : I , Lemme: I\n",
      "Actual : ’ , Lemme: ’\n",
      "Actual : ve , Lemme: ve\n",
      "Actual : just , Lemme: just\n",
      "Actual : been , Lemme: been\n",
      "Actual : sitting , Lemme: sitting\n",
      "Actual : here , Lemme: here\n",
      "Actual : with , Lemme: with\n",
      "Actual : this , Lemme: this\n",
      "Actual : empty , Lemme: empty\n",
      "Actual : cup , Lemme: cup\n",
      "Actual : . , Lemme: .\n",
      "Actual : But , Lemme: But\n",
      "Actual : John , Lemme: John\n",
      "Actual : was , Lemme: wa\n",
      "Actual : always , Lemme: always\n",
      "Actual : impatient , Lemme: impatient\n",
      "Actual : on , Lemme: on\n",
      "Actual : the , Lemme: the\n",
      "Actual : weekends , Lemme: weekend\n",
      "Actual : ; , Lemme: ;\n",
      "Actual : he , Lemme: he\n",
      "Actual : missed , Lemme: missed\n",
      "Actual : the , Lemme: the\n",
      "Actual : formal , Lemme: formal\n",
      "Actual : structure , Lemme: structure\n",
      "Actual : of , Lemme: of\n",
      "Actual : the , Lemme: the\n",
      "Actual : business , Lemme: business\n",
      "Actual : w , Lemme: w\n",
      "Actual : Jesus , Lemme: Jesus\n",
      "Actual : , , Lemme: ,\n",
      "Actual : I , Lemme: I\n",
      "Actual : ’ , Lemme: ’\n",
      "Actual : ve , Lemme: ve\n",
      "Actual : written , Lemme: written\n",
      "Actual : another , Lemme: another\n",
      "Actual : loser , Lemme: loser\n",
      "Actual : . , Lemme: .\n"
     ]
    }
   ],
   "source": [
    "for w in nltk_token:\n",
    "    print(\"Actual : %s , Lemme: %s\" %(w, wordnet_lemmatizer.lemmatize(w)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72a308c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
